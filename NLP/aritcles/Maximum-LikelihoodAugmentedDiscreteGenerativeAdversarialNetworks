这篇文章的工作主要是两个方面：

1.为G构造一个全新的目标函数，用到了ImportanceSampling，将其与D的output结合起来，令训练过程更加稳定同时梯度的方差更低。尽管这个目标函数和RL的方法类似，但是相比之下更能狗降低estimator的方差（强烈建议看原文的3.2Analysis，分析了当D最优以及D经过训练但并没有到最优两种情况下，这个新的目标函数仍然能发挥作用）

2.生成较长序列的时候需要用到多次randomsampling，所以文章还提出了两个降低方差的技巧：第一个是蒙特卡罗树搜索，这个大家都比较熟悉;第二个文章称之为MixedMLE-MaliTraining，就是从真实数据中进行抽样，若序列长度大于N，则固定住前N个词，然后基于前N个词去freelyrunG产生M个样本，一直run到序列结束。

基于前N个词生成后面的词的原因在于条件分布Pd比完整分布要简单，同时能够从真实的样本中得到较强的训练信号。然后逐渐减少N（在实验三中N=30,K=5，K为步长值，训练的时候每次迭代N-K）
